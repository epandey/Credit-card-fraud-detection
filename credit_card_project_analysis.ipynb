{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lljK3dDeXc0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "card=pd.read_csv(\"/content/drive/MyDrive/creditcard.csv/creditcard.csv\")\n",
        "X = card.iloc[:,:-1]\n",
        "y = card['Class']\n",
        "card.head()"
      ],
      "metadata": {
        "id": "NORbDyLQXuEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8cBsnASiiRWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frauds = card.loc[card['Class'] == 1]\n",
        "non_frauds = card.loc[card['Class'] == 0]\n",
        "print(\"We have\", len(frauds), \"fraud data points and\", len(non_frauds), \"regular data points.\")"
      ],
      "metadata": {
        "id": "iOGyL3SyYJDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "metadata": {
        "id": "lJDN0nlBYMBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((\"Size of X_training set:\"  , X_train.shape))\n",
        "print((\"Size of X_testing set:\"  , X_test.shape))\n",
        "print((\"Size of y_training set:\"  , y_train.shape))\n",
        "print((\"Size of y_testing set:\"  , y_test.shape))"
      ],
      "metadata": {
        "id": "lCenmlHMYNt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =Sequential ()\n",
        "model.add(Dense(30, input_dim=30, activation='relu'))     # kernel_initializer='normal'\n",
        "model.add(Dense(12, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "tZe-9ScQYPvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train.to_numpy(), y_train, epochs=1)"
      ],
      "metadata": {
        "id": "YvOnFEqMYkQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic #\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import ks_2samp\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/creditcard.csv/creditcard.csv')\n",
        "\n",
        "# Checking the first few rows\n",
        "print(df.head())\n",
        "df.isnull().sum().max()\n",
        "\n",
        "\n",
        "#  Bar plot\n",
        "fig, ax = plt.subplots()\n",
        "sns.countplot(x='Class', data=df, ax=ax)\n",
        "ax.set_title('Class Distribution')\n",
        "\n",
        "# Add labels\n",
        "total = len(df)\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.annotate(f'{int(height)}\\n{height/total:.2%}', (p.get_x() + p.get_width() / 2., height),\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "# fitting labels\n",
        "ax.set_ylim(0, ax.get_ylim()[1] * 1.1)\n",
        "\n",
        "plt.show()\n",
        "fig.savefig('class_distribution_bar_plot.png')  # Save the figure\n",
        "\n",
        "\n",
        "\n",
        "# histogram\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "num_bins = 40\n",
        "\n",
        "# Histograma para a classe \"Normal\"\n",
        "ax1.hist(df.Time[df.Class == 0], bins=num_bins, color='blue', alpha=0.5, label='Normal')\n",
        "\n",
        "ax1.set_xlabel('Time (seconds)')\n",
        "ax1.set_ylabel('Transactions - Normal ')\n",
        "ax1.set_title('Time Histogram for Normal X Fraud Transactions')\n",
        "\n",
        "# Adiciona um segundo eixo y para a escala de \"Fraude\"\n",
        "ax2 = ax1.twinx()\n",
        "ax2.hist(df.Time[df.Class == 1], bins=num_bins, color='red', alpha=0.5, label='Fraud')\n",
        "\n",
        "ax2.set_ylabel('Transactions - Fraud')\n",
        "\n",
        "# Configuração da legenda\n",
        "lines, labels = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines + lines2, labels + labels2, loc='upper right')\n",
        "\n",
        "\n",
        "plt.show()\n",
        "fig.savefig('transaction_time_histogram.png')  # Save the figure\n",
        "\n",
        "\n",
        "\n",
        "# boxplots\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(3,5), sharex=True)\n",
        "\n",
        "sns.boxplot(x=df.Class, y=df.Amount, showmeans=True, ax=ax)\n",
        "plt.ylim((-20, 400))\n",
        "plt.xticks([0, 1], ['Normal', 'Fraud'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('transaction_amount_boxplot.png')  # Save the figure\n",
        "\n",
        "\n",
        "\n",
        "# Feature Selection techniques\n",
        "\n",
        "\n",
        "# dataframe with independent variables\n",
        "X = df[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
        "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
        "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28'\n",
        "       , 'Amount'\n",
        "        ]]\n",
        "\n",
        "#intercept constant\n",
        "X_int = sm.add_constant(X)\n",
        "\n",
        "# LR model\n",
        "model = sm.Logit(df['Class'], X_int)\n",
        "result = model.fit()\n",
        "\n",
        "# List os variables that didnt pass the tests\n",
        "list_variables_to_drop = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Heteroscedasticity\n",
        "\n",
        "\n",
        "X_temp = X_int.copy()\n",
        "X_temp['const'] = 1\n",
        "\n",
        "# DataFrame to input Breusch-Pagan tests\n",
        "bp_results = pd.DataFrame(columns=['Feature', 'Breusch-Pagan', 'P-value'])\n",
        "\n",
        "\n",
        "for variavel in X_int.columns:\n",
        "    bp_test = het_breuschpagan(df['Class'], X_temp[[variavel, 'const']])\n",
        "    bp_results = bp_results._append(pd.DataFrame({'Feature': [variavel], 'Breusch-Pagan': [bp_test[0]], 'P-value': [bp_test[1]]}), ignore_index=True)\n",
        "\n",
        "\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "#putting variables in a list\n",
        "for i in bp_results[bp_results['P-value'] > 0.05]['Feature']:\n",
        "  if i not in list_variables_to_drop:\n",
        "    list_variables_to_drop.append(i)\n",
        "\n",
        "bp_results[bp_results['P-value'] > 0.05]\n",
        "\n",
        "\n",
        "# Autocorrelation of the residuals\n",
        "\n",
        "# Durbin-Watson test\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "residuals = result.resid_response.copy()\n",
        "dw = durbin_watson(residuals)\n",
        "print('Durbin-Watson test = ', dw)\n",
        "\n",
        "\n",
        "# Correlation between the independent variables\n",
        "\n",
        "# VIF\n",
        "vif = pd.DataFrame()\n",
        "vif[\"Variável\"] = X_int.columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(X_int.values, i) for i in range(X_int.shape[1])]\n",
        "\n",
        "vif[vif['VIF']>5]\n",
        "#Correlation matrix\n",
        "corr = X.corr()\n",
        "\n",
        "# Show only corr up to 0.4\n",
        "mask = corr.abs() <= 0.4\n",
        "corr_masked = corr.mask(mask)\n",
        "corr_masked = corr_masked.applymap(lambda x: x*100 if abs(x) > 0.35 else np.nan)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "sns.heatmap(corr_masked, xticklabels=corr.columns, yticklabels=corr.columns,\n",
        "            linewidths=0.1, cmap=\"coolwarm\", ax=ax, annot=True, fmt='.0f', annot_kws={\"size\": 8})\n",
        "ax.set_title('Correlation Matrix')\n",
        "\n",
        "\n",
        "plt.show()\n",
        "fig.savefig('correlation_matrix.png')  # Save the figure\n",
        "\n",
        "list_variables_to_drop += ['V2']\n",
        "\n",
        "# Kolmogorov-Smirnov test\n",
        "# KS test\n",
        "ks_results = pd.DataFrame(columns=['Feature', 'D_test', 'P-value'])\n",
        "\n",
        "for col in X.columns:\n",
        "    label_1 = df[df['Class'] == 0][col]\n",
        "    label_2 = df[df['Class'] == 1][col]\n",
        "    statistic, p_value = ks_2samp(label_1, label_2)\n",
        "    ks_results = ks_results._append({'Feature': col, 'D_test': statistic, 'P-value': p_value}, ignore_index=True)\n",
        "\n",
        "# showing results\n",
        "ks_results = pd.DataFrame(ks_results)\n",
        "for i in ks_results[ks_results['D_test'] <= 0.11]['Feature']:\n",
        "  if i not in list_variables_to_drop:\n",
        "    list_variables_to_drop.append(i)\n",
        "\n",
        "ks_results[ks_results['D_test'] <= 0.11]\n",
        "\n",
        "list_variables_to_drop\n",
        "\n",
        "\n",
        "column_names = df.drop(['Class', 'Amount', 'Time'], axis=1).columns\n",
        "num_plots = len(column_names)\n",
        "df_class_0 = df[df.Class == 0]\n",
        "df_class_1 = df[df.Class == 1]\n",
        "\n",
        "fig, ax = plt.subplots(nrows=7, ncols=4, figsize=(18,18))\n",
        "fig.subplots_adjust(hspace=1, wspace=1)\n",
        "\n",
        "idx = 0\n",
        "for col in column_names:\n",
        "    idx += 1\n",
        "    plt.subplot(7, 4, idx)\n",
        "    sns.kdeplot(df_class_0[col], label=\"Class 0\", fill=True)\n",
        "    sns.kdeplot(df_class_1[col], label=\"Class 1\", fill=True)\n",
        "    plt.title(col, fontsize=10)\n",
        "plt.tight_layout()\n",
        "# plt.savefig()\n",
        "\n",
        "\n",
        "# Standardize Time and Amount\n",
        "# Standardize Time and Amount\n",
        "df_clean = df.copy()\n",
        "for i in list_variables_to_drop:\n",
        "  if i in df_clean.columns:\n",
        "    df_clean.drop(i,axis=1, inplace=True)\n",
        "\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "df_clean['std_amount'] = std_scaler.fit_transform(df_clean['Amount'].values.reshape(-1, 1))\n",
        "df_clean['std_time'] = std_scaler.fit_transform(df_clean['Time'].values.reshape(-1, 1))\n",
        "df_clean.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
        "df_clean.head()\n",
        "\n",
        "\n",
        "# Train and Test split\n",
        "\n",
        "X = df_clean.drop('Class', axis=1)\n",
        "y = df_clean['Class']\n",
        "#SMOTE\n",
        "smote = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=7)\n",
        "\n",
        "#RandomUnderSampling\n",
        "rus = RandomUnderSampler()\n",
        "\n",
        "#Class weight\n",
        "count_class_1 = y.value_counts()[0]\n",
        "count_class_2 = y.value_counts()[1]\n",
        "ratio = count_class_1/count_class_2\n",
        "class_weight = {1:ratio, 0:1}\n",
        "\n",
        "#ADASYN\n",
        "adasyn = ADASYN(sampling_strategy=1, n_neighbors=5, random_state=7)\n",
        "\n",
        "# Applying the model\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "roc_aucs = []\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "lists_metrics = [accuracies,precisions,recalls,f1_scores,roc_aucs,fpr_list,tpr_list]\n",
        "\n",
        "def model_lr(X_train, y_train, X_test, y_test, class_weight_t, lists, random_state=None):\n",
        "  np.random.seed(2)\n",
        "  lr = LogisticRegression(class_weight=class_weight_t, random_state=random_state)\n",
        "  lr.fit(X_train, y_train)\n",
        "  y_pred = lr.predict(X_test)\n",
        "  y_pred_proba = lr.predict_proba(X_test)[:, 1]\n",
        "  fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "  lists[5].append(fpr)\n",
        "  lists[6].append(tpr)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  f1 = f1_score(y_test, y_pred)\n",
        "  roc_auc = roc_auc_score(y_test, y_pred)\n",
        "  lists[0].append(accuracy)\n",
        "  lists[1].append(precision)\n",
        "  lists[2].append(recall)\n",
        "  lists[3].append(f1)\n",
        "  lists[4].append(roc_auc)\n",
        "  return lists\n",
        "\n",
        "\n",
        "#SMOTE\n",
        "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X, y, stratify=y, shuffle=True, random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_smote, y_train_smote)\n",
        "lists_metrics_smote = model_lr(X_train_smote, y_train_smote, X_test_smote, y_test_smote, None, lists_metrics, random_state=42)\n",
        "\n",
        "\n",
        "#RandomUnderSampler\n",
        "X_train_rus, X_test_rus,  y_train_rus, y_test_rus = train_test_split(X, y, stratify=y, shuffle=True, random_state=123)\n",
        "X_train_rus, y_train_rus = rus.fit_resample(X_train_rus, y_train_rus)\n",
        "lists_metrics_rus = model_lr(X_train_rus, y_train_rus, X_test_rus, y_test_rus, None, lists_metrics, random_state=123)\n",
        "\n",
        "\n",
        "#ADASYN\n",
        "X_train_adasyn, X_test_adasyn, y_train_adasyn, y_test_adasyn = train_test_split(X, y, stratify=y, shuffle=True, random_state=456)\n",
        "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_adasyn, y_train_adasyn)\n",
        "lists_metrics_adasyn = model_lr(X_train_adasyn, y_train_adasyn, X_test_adasyn, y_test_adasyn, None, lists_metrics, random_state=456)\n",
        "\n",
        "\n",
        "#Class Weight\n",
        "X_train_cw, X_test_cw, y_train_cw, y_test_cw = train_test_split(X, y, stratify=y, shuffle=True, random_state=987)\n",
        "lists_metrics_cw = model_lr(X_train_cw, y_train_cw, X_test_cw, y_test_cw, class_weight, lists_metrics, random_state=987)\n",
        "\n",
        "\n",
        "#no balancing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, shuffle=True, random_state=1345)\n",
        "lists_metrics = model_lr(X_train, y_train, X_test, y_test, None, lists_metrics, random_state=1345)\n",
        "\n",
        "\n",
        "# Models evaluation\n",
        "models = ['SMOTE','Random Under-Sampling', 'ADASYN', 'Weighted Classes', 'No Balancing']\n",
        "colors = ['blue', 'green', 'orange', 'red', 'yellow']\n",
        "\n",
        "\n",
        "def bar_plot(evaluation_m, ylabel,title):\n",
        "  plt.figure(figsize=(9, 2))\n",
        "  plt.bar(models, evaluation_m, color=colors)\n",
        "  plt.xlabel('Models')\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.title(title, pad=20)\n",
        "  plt.ylim([0, 1.1])\n",
        "\n",
        "  for i, acc in enumerate(evaluation_m):\n",
        "      plt.text(i, acc, f'{acc:.2%}', ha='center', va='bottom')\n",
        "\n",
        "\n",
        "\n",
        "bar_plot(lists_metrics[0],'Accuracy','Models Accuracys')\n",
        "plt.savefig('accuracy_bar_plot.png')  # Save the figure\n",
        "plt.close()\n",
        "\n",
        "bar_plot(lists_metrics[1],'Precision','Models Precision')\n",
        "plt.savefig('precision_bar_plot.png')  # Save the figure\n",
        "plt.close()\n",
        "bar_plot(lists_metrics[2],'Recall','Models recall')\n",
        "plt.savefig('recall_bar_plot.png')  # Save the figure\n",
        "plt.close()\n",
        "bar_plot(lists_metrics[3],'F1 scores','Models F1 score')\n",
        "plt.savefig('f1_score_bar_plot.png')  # Save the figure\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# Plot ROC-curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "for fpr, tpr, model in zip(lists_metrics[5], lists_metrics[6], [smote, rus, adasyn, class_weight, None ]):\n",
        "    plt.plot(fpr, tpr, label='Model: {}'.format(model))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Each Model')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig.savefig('ROCcurve.png')\n",
        "\n",
        "\n",
        "data = {\n",
        "    'Model': models,\n",
        "    'Accuracy': lists_metrics[0],\n",
        "    'Precision': lists_metrics[1],\n",
        "    'Recall': lists_metrics[2],\n",
        "    'F1 Score': lists_metrics[3],\n",
        "    'ROC AUC': lists_metrics[4]\n",
        "}\n",
        "\n",
        "metrics = pd.DataFrame(data)\n",
        "print(metrics)\n",
        "\n",
        "\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Plotting the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RU44bG4IhLz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas scikit-learn imbalanced-learn tensorflow scikit-plot\n",
        "\n"
      ],
      "metadata": {
        "id": "mAqehYk98Sld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ann #\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/creditcard.csv/creditcard.csv\")\n",
        "\n",
        "# Select features and target\n",
        "X = data.drop('Class', axis=1)  # assuming 'Class' is the target column\n",
        "y = data['Class']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# ANN model architecture with dropout to reduce overfitting\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=X_train_smote.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.8))  # Dropout layer to reduce overfitting\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.8))  # Another dropout layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_smote, y_train_smote, epochs=10, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.3).astype(\"int32\")  # Adjust the threshold to 0.3\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "fRv_ajDflgA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ann vis #\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "import scikitplot as skplt\n",
        "\n",
        "# Function to plot ROC Curve\n",
        "def plot_roc_curve(y_test, y_pred_proba):\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:0.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot Precision-Recall Curve\n",
        "def plot_precision_recall_curve(y_test, y_pred_proba):\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "    average_precision = average_precision_score(y_test, y_pred_proba)\n",
        "\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.plot(recall, precision, color='blue', lw=2, label=f'AP = {average_precision:0.2f}')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.show()\n",
        "\n",
        "# Get predicted probabilities for the positive class\n",
        "y_pred_proba = model.predict(X_test)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plot_roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plot_precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred, figsize=(6,6))\n",
        "plt.show()\n",
        "\n",
        "# Plot Cumulative Gains Chart\n",
        "# Adjusting the Cumulative Gains Chart Plotting\n",
        "if y_pred_proba.shape[1] == 1:\n",
        "    # For binary classification, the second column (index 1) can be assumed as 1 - y_pred_proba\n",
        "    y_pred_proba_adjusted = np.hstack([1 - y_pred_proba, y_pred_proba])\n",
        "    skplt.metrics.plot_cumulative_gain(y_test, y_pred_proba_adjusted)\n",
        "else:\n",
        "    # If y_pred_proba has two columns, use as is\n",
        "    skplt.metrics.plot_cumulative_gain(y_test, y_pred_proba)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "2zO5iMjGBK0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import scikitplot as skplt\n",
        "\n",
        "\n",
        "# Prepare the data (feature selection, scaling, splitting)\n",
        "# Load your dataset\n",
        "# Replace this with the path to your dataset\n",
        "data =pd.read_csv(\"/content/drive/MyDrive/creditcard.csv/creditcard.csv\")\n",
        "\n",
        "# Select features and target\n",
        "X = data.drop('Class', axis=1)  # assuming 'Class' is the target column\n",
        "y = data['Class']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create a decision tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=30, max_depth=3)\n",
        "\n",
        "# Train the model\n",
        "dt_classifier.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "y_pred_proba_dt = dt_classifier.predict_proba(X_test)[:, 1]  # Probability for the positive class\n",
        "\n",
        "# Print classification report and confusion matrix\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print(confusion_matrix(y_test, y_pred_dt))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "import scikitplot as skplt\n",
        "\n",
        "# Function to plot ROC Curve\n",
        "def plot_roc_curve(y_test, y_pred_proba):\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:0.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot Precision-Recall Curve\n",
        "def plot_precision_recall_curve(y_test, y_pred_proba):\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "    average_precision = average_precision_score(y_test, y_pred_proba)\n",
        "\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.plot(recall, precision, color='blue', lw=2, label=f'AP = {average_precision:0.2f}')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.show()\n",
        "\n",
        "# Get predicted probabilities for the positive class\n",
        "y_pred_proba = model.predict(X_test)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plot_roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plot_precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred, figsize=(6,6))\n",
        "plt.show()\n",
        "\n",
        "# Plot Cumulative Gains Chart\n",
        "# Adjusting the Cumulative Gains Chart Plotting\n",
        "# Adjusting the Cumulative Gains Chart Plotting for Decision Tree\n",
        "# Plot Cumulative Gains Chart\n",
        "try:\n",
        "    if y_pred_proba_dt.shape[1] == 1:\n",
        "        y_pred_proba_dt_adjusted = np.hstack([1 - y_pred_proba_dt, y_pred_proba_dt])\n",
        "        skplt.metrics.plot_cumulative_gain(y_test, y_pred_proba_dt_adjusted)\n",
        "    else:\n",
        "        skplt.metrics.plot_cumulative_gain(y_test, y_pred_proba_dt)\n",
        "except IndexError:\n",
        "    # If y_pred_proba_dt does not have a second dimension, handle accordingly\n",
        "    print(\"Error in probability shape: \", y_pred_proba_dt.shape)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jf3fcdvbDblt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}